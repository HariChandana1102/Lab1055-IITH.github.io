<!DOCTYPE html>
<html>
<head><meta charset="UTF-8"><title>Lab 1055 | Home</title><link rel="stylesheet" href="style.css"></head>
<body>
  <header class="hero">
    <img src="assets/hero.jpg" alt="Lab 1055 Logo">
    <h1>Lab 1055 ‑ IITH</h1>
    <p>AI & Vision‑Language Research Group</p>
  </header>
  <nav>
  <ul>
    <li><a href="index.html">Home</a></li>
     <li><a href="research.html">Research</a></li>
    <li><a href="team.html">Team</a></li>
    <li><a href="news.html">News and Awards</a></li>
    <li><a href="vacancies.html">Vacancies</a></li>
    <li><a href="contact.html">Contact</a></li>
  </ul>
</nav>
  <div class="container">
    <section>
      <h2>About Us</h2>
      <p>Our research group, Lab 1055, works at the intersection of the theory and application of machine learning - with a focus on applications in computer vision. With a strong interest in the mathematical fundamentals and a passion for real-world application, our group aims on being at the forefront of the field, by carrying out impactful research in the areas of deep learning, machine learning and computer vision, guided by application contexts derived from real-world use.</p>
      <p> Keywords: Deep Learning, Machine Learning, Computer Vision, Explainable AI</p>
      <p>Our problems of interest in recent times have focused on learning reliable and robust AI/ML systems in ever-evolving environments. Some of the problems we tackle include:
        <ul style="margin-left: 30px;">
        <li"><span style="font-weight: 900;">Explainable and robust machine/deep learning: This includes problems on explainable AI (largely ante-hoc inherently interpretable methods), use of causality in machine learning, adversarial and attributional robustness, disentanglement of latent variables, compositionality in deep learning models.</li>
        <li><strong>Organic lifelong learning:</strong> This direction focuses on learning continuously in evolving environments with whatever data and labels are available at hand; this includes settings such as continual learning, zero-shot learning, few-shot learning, active learning, domain adaptation, domain generalization and more importantly, the amalgamation of these settings that could organically arise in real-world settings.</li>
        <li><strong>Multimodal vision-language models:</strong> Our efforts herein focus on the recent emergence of multimodal vision-language models that allow us to parse images/videos and text to perceive, represent as well as communicate with users effectively.</p></li>
        </ul>
      <div style="margin-top: 20px;"></div>
      <p>From an application standpoint, problems of our recent interest include:</p>
        <ul style="margin-left: 30px;">
        <li>Agriculture: Plant phenotyping using computer vision</li> 
        <li>Drone-based vision: Detection of objects from drone imagery, as well as low-resolution imagery</li>
         <li>Autonomous navigation: adding levels of autonomy to driving vehicles in developing countries, focusing on India</li>
         <li>Human behavior understanding: Detection of emotions, human poses, gestures, etc of the human body using images and videos</li>
        <ul>
    </section>
    <section>
      <h2>Latest Update</h2>
      <p><strong>June 2025:</strong> Our paper on Open‑World Detection accepted at CVPR!</p>
    </section>
  </div>
  <footer>© 2025 Lab 1055, IITH</footer>
</body>
</html>
